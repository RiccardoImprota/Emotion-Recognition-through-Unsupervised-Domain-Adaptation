{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project consists in comparing at least two different methods for unsupervised domain adaptation and showing the results in a table. The results shall show performance on the source dataset, and performance on the target dataset. Moreover, the upper bound will be evaluated by training and testing the models on the target dataset as a sort of oracle predictor.\n",
    "\n",
    "\n",
    "Google Colab was used for the project for computational reasons."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initialization\n",
    "\n",
    "Since I'm using Google Colab for computational reasons, I will structure this notebook by putting in these first cells all relevant hyperparameters and libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%cd 'insert path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 30\n",
    "learning_rate=0.0001\n",
    "source_train_dir='AFE\\\\train'\n",
    "source_test_dir='AFE\\\\test'\n",
    "target_train_dir='FER2013\\\\train'\n",
    "target_test_dir='FER2013\\\\test'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for resizing, converting to grayscale, normalization\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "source_train_data = datasets.ImageFolder(source_train_dir, transform=transform)\n",
    "source_test_data = datasets.ImageFolder(source_test_dir, transform=transform)\n",
    "target_train_data = datasets.ImageFolder(target_train_dir, transform=transform)\n",
    "target_test_data = datasets.ImageFolder(target_test_dir, transform=transform)\n",
    "print(\"imagefolder done\")\n",
    "\n",
    "\n",
    "# Create data loaders for batching the data\n",
    "source_train_loader = DataLoader(source_train_data, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "source_test_loader = DataLoader(source_test_data, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "target_train_loader = DataLoader(target_train_data, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "target_test_loader = DataLoader(target_test_data, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "print(\"DataLoader done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the data is made up of tensors for safety\n",
    "print(f'Type of first instance in source train data: {type(source_train_data[0][0])}')\n",
    "print(f'Type of first instance in target train data: {type(target_train_data[0][0])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Network architecture\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobilenetv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.mobilenet_v3_small(weights='DEFAULT')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# We're not freezing anything\n",
    "#for param in model.parameters():\n",
    "  #param.requires_grad = False\n",
    "\n",
    "\n",
    "#Changing number of classes of output\n",
    "print(model.classifier)\n",
    "model.classifier[3] = nn.Linear(1024, 7).to(device)\n",
    "print(model.classifier)\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model.classifier)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficientnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.efficientnet_v2_s(weights='DEFAULT')\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#Changing number of classes of output\n",
    "print(model.classifier)\n",
    "model.classifier[1] = nn.Linear(1280, 7).to(device)\n",
    "print(model.classifier)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# Coral\n",
    "\n",
    "## Coral Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORAL loss\n",
    "def coral_loss(source, target):\n",
    "    source_mean = torch.mean(source, dim=0, keepdim=True)\n",
    "    target_mean = torch.mean(target, dim=0, keepdim=True)\n",
    "    source_cov = (source - source_mean).t() @ (source - source_mean) / (source.size(0) - 1)\n",
    "    target_cov = (target - target_mean).t() @ (target - target_mean) / (target.size(0) - 1)\n",
    "    loss = torch.norm(source_cov - target_cov, p='fro')\n",
    "    return loss\n",
    "\n",
    "# Define the task-specific loss\n",
    "cross_entropy_loss  = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "progress_bar = tqdm(enumerate(zip(source_train_loader, target_train_loader)), total=len(source_train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar.reset()\n",
    "\n",
    "    for i, ((source_inputs, source_labels), (target_inputs, _)) in enumerate(zip(source_train_loader, target_train_loader)):\n",
    "\n",
    "        source_inputs = source_inputs.to(device)\n",
    "        source_labels = source_labels.to(device)\n",
    "        target_inputs = target_inputs.to(device)\n",
    "        \n",
    "        source_outputs = model(source_inputs)\n",
    "        target_outputs = model(target_inputs)\n",
    "\n",
    "        # loss\n",
    "        cross_entropy_loss_value = cross_entropy_loss(source_outputs, source_labels)\n",
    "        coral_loss_value  = coral_loss(source_outputs, target_outputs)\n",
    "        loss = (coral_loss_value*0.7) + (cross_entropy_loss_value*0.3)\n",
    "\n",
    "\n",
    "        # optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(source_outputs.data, 1)\n",
    "        total += source_labels.size(0)\n",
    "        correct += (predicted == source_labels).sum().item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / (i + 1)}, Accuracy: {correct / total * 100}%')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(source_train_loader)}, Accuracy: {correct / total * 100}%')\n",
    "    progress_bar.refresh()\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()  # set the model to evaluation mode\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(target_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Target Accuracy: {correct / total * 100}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): #reducing memory consumption\n",
    "    for i, (inputs, labels) in enumerate(source_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'source Test Accuracy: {correct / total * 100}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(target_train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Target train Accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# MMD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.mobilenet_v3_small(weights='DEFAULT')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# We're not freezing anything\n",
    "#for param in model.parameters():\n",
    "  #param.requires_grad = False\n",
    "\n",
    "\n",
    "#Changing number of classes of output\n",
    "print(model.classifier)\n",
    "model.classifier[3] = nn.Linear(1024, 7).to(device)\n",
    "print(model.classifier)\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel_matrix(x, y, sigma):\n",
    "    x_size = x.size(0)\n",
    "    y_size = y.size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1)\n",
    "    y = y.unsqueeze(0)\n",
    "    tiled_x = x.expand(x_size, y_size, dim)\n",
    "    tiled_y = y.expand(x_size, y_size, dim)\n",
    "    return torch.exp(-((tiled_x - tiled_y)**2).sum(2) / (2.0 * sigma**2))\n",
    "\n",
    "# gaussian kernel for mmd loss, sigma=1\n",
    "def compute_mmd(x, y, sigma):\n",
    "    x_kernel = gaussian_kernel_matrix(x, x, sigma)\n",
    "    y_kernel = gaussian_kernel_matrix(y, y, sigma)\n",
    "    xy_kernel = gaussian_kernel_matrix(x, y, sigma)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd\n",
    "\n",
    "cross_entropy_loss  = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "progress_bar = tqdm(enumerate(zip(source_train_loader, target_train_loader)), total=len(source_train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar.reset()\n",
    "\n",
    "    for i, ((source_inputs, source_labels), (target_inputs, _)) in enumerate(zip(source_train_loader, target_train_loader)):\n",
    "        source_inputs = source_inputs.to(device)\n",
    "        source_labels = source_labels.to(device)\n",
    "        target_inputs = target_inputs.to(device)\n",
    "        source_outputs = model(source_inputs)\n",
    "        target_outputs = model(target_inputs)\n",
    "\n",
    "        # loss\n",
    "        cross_entropy_loss_value = cross_entropy_loss(source_outputs, source_labels)\n",
    "        mmd_loss_value  = compute_mmd(source_outputs, target_outputs,1)\n",
    "        loss = (mmd_loss_value*0.5) + (cross_entropy_loss_value*0.5)\n",
    "\n",
    "\n",
    "        # optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(source_outputs.data, 1)\n",
    "        total += source_labels.size(0)\n",
    "        correct += (predicted == source_labels).sum().item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / (i + 1)}, Accuracy: {correct / total * 100}%')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(source_train_loader)}, Accuracy: {correct / total * 100}%')\n",
    "    progress_bar.refresh()\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval() \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(target_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Target Accuracy: {correct / total * 100}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for i, (inputs, labels) in enumerate(source_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Source Test Accuracy: {correct / total * 100}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for i, (inputs, labels) in enumerate(target_train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Target train Accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Oracle Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.mobilenet_v3_small(weights='DEFAULT')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# We're not freezing anything\n",
    "#for param in model.parameters():\n",
    "  #param.requires_grad = False\n",
    "\n",
    "\n",
    "#Changing number of classes of output\n",
    "print(model.classifier)\n",
    "model.classifier[3] = nn.Linear(1024, 7).to(device)\n",
    "print(model.classifier)\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model.classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "progress_bar = tqdm(total=len(target_train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    progress_bar.reset()\n",
    "\n",
    "    for i, (source_inputs, source_labels) in enumerate(target_train_loader):\n",
    "\n",
    "        source_inputs = source_inputs.to(device)\n",
    "        source_labels = source_labels.to(device)\n",
    "        source_outputs = model(source_inputs)\n",
    "\n",
    "        loss = cross_entropy_loss(source_outputs, source_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(source_outputs.data, 1)\n",
    "        total += source_labels.size(0)\n",
    "        correct += (predicted == source_labels).sum().item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / (i + 1)}, Accuracy: {correct / total * 100}%')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(target_train_loader)}, Accuracy: {correct / total * 100}%')\n",
    "    progress_bar.refresh()\n",
    "\n",
    "progress_bar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(target_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Target Accuracy: {correct / total * 100}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
