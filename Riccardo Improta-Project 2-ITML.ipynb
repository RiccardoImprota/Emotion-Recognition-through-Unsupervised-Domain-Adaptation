{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project consists in comparing at least two different methods for unsupervised domain adaptation and showing the results in a table. The results shall show performance on the source dataset, and performance on the target dataset. Moreover, the upper bound will be evaluated by training and testing the models on the target dataset as a sort of oracle predictor.\n",
    "\n",
    "\n",
    "Google Colab was used for the project for computational reasons."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initialization\n",
    "\n",
    "Since I'm using Google Colab for computational reasons, I will structure this notebook by putting in these first cells all relevant hyperparameters and libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from coral_pytorch.losses import CoralLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 30\n",
    "learning_rate=0.0001\n",
    "source_train_dir='AFE\\\\train'\n",
    "source_test_dir='AFE\\\\test'\n",
    "target_train_dir='FER2013\\\\train'\n",
    "target_test_dir='FER2013\\\\test'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagefolder done\n",
      "DataLoader done\n"
     ]
    }
   ],
   "source": [
    "# Define the transformations for resizing, converting to grayscale\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Create instances of the source and target datasets\n",
    "source_train_data = datasets.ImageFolder(source_train_dir, transform=transform)\n",
    "source_test_data = datasets.ImageFolder(source_test_dir, transform=transform)\n",
    "target_train_data = datasets.ImageFolder(target_train_dir, transform=transform)\n",
    "target_test_data = datasets.ImageFolder(target_test_dir, transform=transform)\n",
    "print(\"imagefolder done\")\n",
    "\n",
    "\n",
    "# Create data loaders for batching the data\n",
    "source_train_loader = DataLoader(source_train_data, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "source_test_loader = DataLoader(source_test_data, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "target_train_loader = DataLoader(target_train_data, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "target_test_loader = DataLoader(target_test_data, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "print(\"DataLoader done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first instance in source train data: <class 'torch.Tensor'>\n",
      "Type of first instance in target train data: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Type of first instance in source train data: {type(source_train_data[0][0])}')\n",
    "print(f'Type of first instance in target train data: {type(target_train_data[0][0])}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Network architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "  (1): Hardswish()\n",
      "  (2): Dropout(p=0.2, inplace=True)\n",
      "  (3): Linear(in_features=1024, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=models.mobilenet_v3_small(weights='DEFAULT')\n",
    "model = model.to(device)\n",
    "\n",
    "#for param in model.parameters():\n",
    "  #param.requires_grad = False\n",
    "\n",
    "model.classifier[3] = nn.Linear(1024, 7).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model.classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.2, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.2, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=models.efficientnet_v2_s(weights='DEFAULT')\n",
    "model = model.to(device)\n",
    "print(model.classifier)\n",
    "#for param in model.parameters():\n",
    "  #param.requires_grad = False\n",
    "\n",
    "model.classifier[1] = nn.Linear(1280, 7).to(device)\n",
    "\n",
    "#model.classifier[1] =torch.nn.Sequential(\n",
    "#    torch.nn.Dropout(0.5),\n",
    "#    torch.nn.Linear(1280, 7).to(device)\n",
    "#)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=0.0001)\n",
    "print(model.classifier)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# Coral\n",
    "\n",
    "## Coral Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CORAL loss\n",
    "def coral_loss(source, target):\n",
    "    # Source and target are the feature representations of source and target datasets.\n",
    "    # They should be 2D Tensors, where the number of rows should be the number of instances\n",
    "    # and the number of columns should be the number of features.\n",
    "    # So, source.size() = (num_source_instances, num_features)\n",
    "    # and target.size() = (num_target_instances, num_features)\n",
    "\n",
    "    # Compute the mean of source and target\n",
    "    source_mean = torch.mean(source, dim=0, keepdim=True)\n",
    "    target_mean = torch.mean(target, dim=0, keepdim=True)\n",
    "\n",
    "    # Compute the covariance of source and target\n",
    "    source_cov = (source - source_mean).t() @ (source - source_mean) / (source.size(0) - 1)\n",
    "    target_cov = (target - target_mean).t() @ (target - target_mean) / (target.size(0) - 1)\n",
    "\n",
    "    # Compute the Frobenius norm of the covariance difference\n",
    "    loss = torch.norm(source_cov - target_cov, p='fro')\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Define the task-specific loss\n",
    "cross_entropy_loss  = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Loss: 8.670728371698907, Accuracy: 80.16362615087796%: 100%|██████████| 427/427 [01:44<00:00,  4.09it/s]  \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "progress_bar = tqdm(enumerate(zip(source_train_loader, target_train_loader)), total=len(source_train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar.reset()\n",
    "\n",
    "    for i, ((source_inputs, source_labels), (target_inputs, _)) in enumerate(zip(source_train_loader, target_train_loader)):\n",
    "\n",
    "        source_inputs = source_inputs.to(device)\n",
    "        source_labels = source_labels.to(device)\n",
    "        target_inputs = target_inputs.to(device)\n",
    "        # Forward pass\n",
    "        source_outputs = model(source_inputs)\n",
    "        target_outputs = model(target_inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        cross_entropy_loss_value = cross_entropy_loss(source_outputs, source_labels)\n",
    "        coral_loss_value  = coral_loss(source_outputs, target_outputs)\n",
    "        loss = (coral_loss_value*0.7) + (cross_entropy_loss_value*0.3)\n",
    "\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(source_outputs.data, 1)\n",
    "        total += source_labels.size(0)\n",
    "        correct += (predicted == source_labels).sum().item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / (i + 1)}, Accuracy: {correct / total * 100}%')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(source_train_loader)}, Accuracy: {correct / total * 100}%')\n",
    "    progress_bar.refresh()\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Target Accuracy: 44.23237670660351%\n",
      "source Test Accuracy: 85.97223748306047%\n",
      "Target train Accuracy: 44.07677035076109%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()  # set the model to evaluation mode\n",
    "\n",
    "# Compute target accuracy using test_target_dataloader\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(target_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Target Accuracy: {correct / total * 100}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # disable gradient computation\n",
    "    for i, (inputs, labels) in enumerate(source_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'source Test Accuracy: {correct / total * 100}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # disable gradient computation\n",
    "    for i, (inputs, labels) in enumerate(target_train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Target train Accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# MMD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "  (1): Hardswish()\n",
      "  (2): Dropout(p=0.2, inplace=True)\n",
      "  (3): Linear(in_features=1024, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=models.mobilenet_v3_small(weights='DEFAULT')\n",
    "model = model.to(device)\n",
    "\n",
    "#for param in model.parameters():\n",
    "  #param.requires_grad = False\n",
    "\n",
    "model.classifier[3] = nn.Linear(1024, 7).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model.classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel_matrix(x, y, sigma):\n",
    "    x_size = x.size(0)\n",
    "    y_size = y.size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1)  # (x_size, 1, dim)\n",
    "    y = y.unsqueeze(0)  # (1, y_size, dim)\n",
    "    tiled_x = x.expand(x_size, y_size, dim)\n",
    "    tiled_y = y.expand(x_size, y_size, dim)\n",
    "    return torch.exp(-((tiled_x - tiled_y)**2).sum(2) / (2.0 * sigma**2))\n",
    "\n",
    "def compute_mmd(x, y, sigma):\n",
    "    x_kernel = gaussian_kernel_matrix(x, x, sigma)\n",
    "    y_kernel = gaussian_kernel_matrix(y, y, sigma)\n",
    "    xy_kernel = gaussian_kernel_matrix(x, y, sigma)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd\n",
    "\n",
    "cross_entropy_loss  = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 5.234048975745011, Accuracy: 82.73426624661148%: 100%|██████████| 427/427 [00:48<00:00,  8.80it/s] \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "progress_bar = tqdm(enumerate(zip(source_train_loader, target_train_loader)), total=len(source_train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar.reset()\n",
    "\n",
    "    for i, ((source_inputs, source_labels), (target_inputs, _)) in enumerate(zip(source_train_loader, target_train_loader)):\n",
    "        source_inputs = source_inputs.to(device)\n",
    "        source_labels = source_labels.to(device)\n",
    "        target_inputs = target_inputs.to(device)\n",
    "        # Forward pass\n",
    "        source_outputs = model(source_inputs)\n",
    "        target_outputs = model(target_inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        cross_entropy_loss_value = cross_entropy_loss(source_outputs, source_labels)\n",
    "        mmd_loss_value  = compute_mmd(source_outputs, target_outputs,1)\n",
    "        loss = (mmd_loss_value*0.5) + (cross_entropy_loss_value*0.5)\n",
    "\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(source_outputs.data, 1)\n",
    "        total += source_labels.size(0)\n",
    "        correct += (predicted == source_labels).sum().item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / (i + 1)}, Accuracy: {correct / total * 100}%')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(source_train_loader)}, Accuracy: {correct / total * 100}%')\n",
    "    progress_bar.refresh()\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Target Accuracy: 31.192532738924488%\n",
      "Source Test Accuracy: 71.11306449840676%\n",
      "Target train Accuracy: 32.25469365007489%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()  # set the model to evaluation mode\n",
    "\n",
    "# Compute target accuracy using test_target_dataloader\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(target_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Target Accuracy: {correct / total * 100}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # disable gradient computation\n",
    "    for i, (inputs, labels) in enumerate(source_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Source Test Accuracy: {correct / total * 100}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # disable gradient computation\n",
    "    for i, (inputs, labels) in enumerate(target_train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Target train Accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Oracle Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "  (1): Hardswish()\n",
      "  (2): Dropout(p=0.2, inplace=True)\n",
      "  (3): Linear(in_features=1024, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=models.mobilenet_v3_small(weights='DEFAULT')\n",
    "model = model.to(device)\n",
    "\n",
    "#for param in model.parameters():\n",
    "  #param.requires_grad = False\n",
    "\n",
    "model.classifier[3] = nn.Linear(1024, 7).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model.classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.3916057722605682, Accuracy: 86.2900135845902%: 100%|██████████| 449/449 [00:25<00:00, 17.42it/s]  \n"
     ]
    }
   ],
   "source": [
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "progress_bar = tqdm(total=len(target_train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    progress_bar.reset()\n",
    "\n",
    "    for i, (source_inputs, source_labels) in enumerate(target_train_loader):\n",
    "\n",
    "        source_inputs = source_inputs.to(device)\n",
    "        source_labels = source_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        source_outputs = model(source_inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = cross_entropy_loss(source_outputs, source_labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(source_outputs.data, 1)\n",
    "        total += source_labels.size(0)\n",
    "        correct += (predicted == source_labels).sum().item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / (i + 1)}, Accuracy: {correct / total * 100}%')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.set_description(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(target_train_loader)}, Accuracy: {correct / total * 100}%')\n",
    "    progress_bar.refresh()\n",
    "\n",
    "progress_bar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Target Accuracy: 46.517135692393424%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()  # set the model to evaluation mode\n",
    "\n",
    "# Compute target accuracy using test_target_dataloader\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(target_test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Target Accuracy: {correct / total * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
